{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import module\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#create session in order to be capable of accessing all Spark API\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Introdution to Spark DataFrame\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#define data schema for file we want to read\n",
    "purchaseSchema = StructType([\n",
    "    StructField(\"Date\", DateType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Total\", FloatType(), True),\n",
    "    StructField(\"Payment\", StringType(), True),\n",
    "])    \n",
    "\n",
    "# read csv file with our defined schema into Spark DataFrame, and use \"tab\" delimiter\n",
    "purchaseDataframe = spark.read.csv(\n",
    "    \"random_sales_data.csv\", \n",
    "    header=True, schema=purchaseSchema, sep=\",\")  # Change sep=\"\\t\" to sep=\",\"\n",
    "purchaseDataframe.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting number of rows, printing dataframe schema and printing statistic of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  100\n",
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Total: float (nullable = true)\n",
      " |-- Payment: string (nullable = true)\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|            Total|\n",
      "+-------+-----------------+\n",
      "|  count|              100|\n",
      "|   mean|982.8642013549804|\n",
      "| stddev| 575.460867997704|\n",
      "|    min|            71.38|\n",
      "|    max|          1999.51|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count number of rows of our dataFrame\n",
    "num_rows = purchaseDataframe.count()\n",
    "print(\"number of rows: \", num_rows)\n",
    "#show our dataFrame schema\n",
    "purchaseDataframe.printSchema()\n",
    "#show statistic of the data we want\n",
    "purchaseDataframe.describe('Total').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new dataFrame from a subset of our existing dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|    City|  Total|\n",
      "+--------+-------+\n",
      "|New York|1999.51|\n",
      "|New York|1690.17|\n",
      "|New York|  78.16|\n",
      "+--------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Total: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create new dataFrame from \"City\" and \"Total\" columns\n",
    "newDataframe = purchaseDataframe.select(purchaseDataframe['City'], \n",
    "                                              purchaseDataframe['Total'])\n",
    "newDataframe.show(3); #menampilkan 3 baris DataFrame baru kita\n",
    "newDataframe.printSchema() #print skema dari DataFrame baru kita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a constant value to every row data in certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|    City|(Total + 10)|\n",
      "+--------+------------+\n",
      "|New York|     2009.51|\n",
      "|New York|     1700.17|\n",
      "|New York|       88.16|\n",
      "+--------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding constant value of 10 to every row data in \"Total\" column\n",
    "purchaseDataframe.select(purchaseDataframe['City'],\n",
    "                         purchaseDataframe['Total']+10).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering dataFrame using our defined condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+--------+-------+-------+\n",
      "|      Date|    Time|       City|    Item|  Total|Payment|\n",
      "+----------+--------+-----------+--------+-------+-------+\n",
      "|2023-02-07|02:47:33|   New York|   Phone|1999.51| PayPal|\n",
      "|2023-06-21|10:46:46|   New York|Keyboard|1690.17| PayPal|\n",
      "|2023-05-30|08:40:31|Los Angeles|   Mouse|1641.63|   Cash|\n",
      "+----------+--------+-----------+--------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter only row data whose \"Total\" column value > 200\n",
    "purchaseDataframe.filter(purchaseDataframe['Total'] > 200).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting dataFrame by certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------+-------+----------+\n",
      "|      Date|    Time|   City|    Item|  Total|   Payment|\n",
      "+----------+--------+-------+--------+-------+----------+\n",
      "|2023-04-04|07:36:51|Chicago|Keyboard|1870.75|Debit Card|\n",
      "|2023-02-09|14:17:55|Chicago|   Phone| 293.42|Debit Card|\n",
      "|2023-12-07|13:07:18|Chicago|  Laptop| 816.82|Debit Card|\n",
      "|2023-06-15|00:16:21|Chicago|   Phone|1963.72|      Cash|\n",
      "+----------+--------+-------+--------+-------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sortedByCity = purchaseDataframe.orderBy('City').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating number of transactions in each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       City|count|\n",
      "+-----------+-----+\n",
      "|    Phoenix|   22|\n",
      "|Los Angeles|   20|\n",
      "|    Chicago|   13|\n",
      "|    Houston|   21|\n",
      "|   New York|   24|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numTransactionEachCity = purchaseDataframe.groupBy(\"City\").count()\n",
    "numTransactionEachCity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Accessing DataFrame\n",
    "Since Spark dataFrame is distributed into clusters, we cannot access it by [row,column] as in pandas dataFrame for example. There is an alternative way to do that by creating new column with \"incremental ID\". Then, we can access by row using \".filter()\" function to our \"incremental ID\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+--------+-------+-----------+-----+\n",
      "|      Date|    Time|       City|    Item|  Total|    Payment|index|\n",
      "+----------+--------+-----------+--------+-------+-----------+-----+\n",
      "|2023-02-07|02:47:33|   New York|   Phone|1999.51|     PayPal|    0|\n",
      "|2023-06-21|10:46:46|   New York|Keyboard|1690.17|     PayPal|    1|\n",
      "|2023-07-03|09:41:10|   New York| Monitor|  78.16| Debit Card|    2|\n",
      "|2023-05-30|08:40:31|Los Angeles|   Mouse|1641.63|       Cash|    3|\n",
      "|2023-02-20|10:38:44|   New York|   Phone|1499.96|Credit Card|    4|\n",
      "|2023-08-15|13:28:17|   New York|Keyboard| 775.31|Credit Card|    5|\n",
      "|2023-09-02|08:17:51|   New York|  Tablet|1387.94|Credit Card|    6|\n",
      "+----------+--------+-----------+--------+-------+-----------+-----+\n",
      "only showing top 7 rows\n",
      "\n",
      "+----------+--------+-----------+-------+-------+-----------+-----+\n",
      "|      Date|    Time|       City|   Item|  Total|    Payment|index|\n",
      "+----------+--------+-----------+-------+-------+-----------+-----+\n",
      "|2023-07-03|09:41:10|   New York|Monitor|  78.16| Debit Card|    2|\n",
      "|2023-05-30|08:40:31|Los Angeles|  Mouse|1641.63|       Cash|    3|\n",
      "|2023-02-20|10:38:44|   New York|  Phone|1499.96|Credit Card|    4|\n",
      "+----------+--------+-----------+-------+-------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import monotonically_increasing_id\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "newPurchasedDataframe = purchaseDataframe.withColumn(\n",
    "    \"index\", monotonically_increasing_id())\n",
    "newPurchasedDataframe.show(7)\n",
    "row2Till4 = newPurchasedDataframe.filter((newPurchasedDataframe['index']>=2) &\n",
    "                                         (newPurchasedDataframe['index']<=4))\n",
    "row2Till4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to access it by row and column, use \".select()\" function we ever used above before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Total|\n",
      "+-----+\n",
      "|78.16|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataRow2ColumnTotal = newPurchasedDataframe.filter(newPurchasedDataframe['index']==2).select('Total')\n",
    "dataRow2ColumnTotal.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SQL query in dataFrame\n",
    "\n",
    "Create a new dataFrame from the subset of our existing dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|  Total|   Payment|\n",
      "+-------+----------+\n",
      "|1999.51|    PayPal|\n",
      "|1690.17|    PayPal|\n",
      "|  78.16|Debit Card|\n",
      "+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#we need to make sql temporary view for our dataFrame\n",
    "purchaseDataframe.createOrReplaceTempView(\"purchaseSql\")\n",
    "\n",
    "#select \"Total\" dan \"Payment\" column from our sql temporary view\n",
    "anotherNewDataframe = spark.sql(\"SELECT Total, Payment FROM purchaseSql\")\n",
    "anotherNewDataframe.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting data by certain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+------+-------+-----------+\n",
      "|      Date|    Time|   City|  Item|  Total|    Payment|\n",
      "+----------+--------+-------+------+-------+-----------+\n",
      "|2023-12-07|13:07:18|Chicago|Laptop| 816.82| Debit Card|\n",
      "|2023-04-09|20:24:19|Chicago| Mouse| 918.36|Credit Card|\n",
      "|2023-06-14|09:32:38|Chicago| Phone|1250.92| Debit Card|\n",
      "|2023-06-15|00:16:21|Chicago| Phone|1963.72|       Cash|\n",
      "|2023-01-16|14:33:11|Chicago| Mouse|1284.71|       Cash|\n",
      "+----------+--------+-------+------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sorting data by \"City\" column alphabetically\n",
    "orderByCity = spark.sql(\"SELECT * FROM purchaseSql ORDER BY City\")\n",
    "orderByCity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last one, we wil show how to filter data with \"Total\" column value > 200, and sort them by \"Payment\" column data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------+-------+-------+\n",
      "|      Date|    Time|   City|    Item|  Total|Payment|\n",
      "+----------+--------+-------+--------+-------+-------+\n",
      "|2023-06-15|00:16:21|Chicago|   Phone|1963.72|   Cash|\n",
      "|2023-11-16|03:32:45|Phoenix|Keyboard| 1684.1|   Cash|\n",
      "|2023-12-04|22:45:48|Phoenix|  Laptop| 281.72|   Cash|\n",
      "|2023-06-16|03:37:18|Chicago| Monitor| 451.94|   Cash|\n",
      "+----------+--------+-------+--------+-------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter nilai kolom Total>50 dan urutkan berdasarkan cara pembayaran\n",
    "filterAndSortWithSQL = spark.sql(\"SELECT * FROM purchaseSql WHERE Total>200 ORDER BY Payment\")\n",
    "filterAndSortWithSQL.show(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
